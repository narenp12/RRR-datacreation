{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1860f753",
   "metadata": {},
   "source": [
    "# Novel classification of papers based on content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5dc3ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import sklearn as sk\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ef96528",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_data = pd.read_csv(\"comp_data.csv\")\n",
    "stats_data = pd.read_csv(\"stats_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992534fe",
   "metadata": {},
   "source": [
    "# Categorizing papers based on content - combining datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "227d3eaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Unnamed: 0",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "category",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "category_code",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "published_date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "updated_date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "authors",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "first_author",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "summary",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "summary_word_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "year",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "afd62f96-6407-483c-9cc6-b351daa65894",
       "rows": [
        [
         "12061",
         "131585",
         "abs-1501.03214v1",
         "Quantifying Prosodic Variability in Middle English Alliterative Poetry",
         "Applications (Statistics)",
         "stat.AP",
         "2015-01-14",
         "2015-01-14",
         "['Roger Bilisoly']",
         "'Roger Bilisoly'",
         "Interest in the mathematical structure of poetry dates back to at least the\n19th century: after retiring from his mathematics position, J. J. Sylvester\nwrote a book on prosody called $\\textit{The Laws of Verse}$. Today there is\ninterest in the computer analysis of poems, and this paper discusses how a\nstatistical approach can be applied to this task. Starting with the definition\nof what Middle English alliteration is, $\\textit{Sir Gawain and the Green\nKnight}$ and William Langland's $\\textit{Piers Plowman}$ are used to illustrate\nthe methodology. Theory first developed for analyzing data from a Riemannian\nmanifold turns out to be applicable to strings allowing one to compute a\ngeneralized mean and variance for textual data, which is applied to the poems\nabove. The ratio of these two variances produces the analogue of the F test,\nand resampling allows p-values to be estimated. Consequently, this methodology\nprovides a way to compare prosodic variability between two texts.",
         "154",
         "2015"
        ],
        [
         "12062",
         "131630",
         "abs-1709.00071v1",
         "Weather impacts expressed sentiment",
         "Applications (Statistics)",
         "stat.AP",
         "2017-08-31",
         "2017-08-31",
         "['Patrick Baylis', 'Nick Obradovich', 'Yury Kryvasheyeu', 'Haohui Chen', 'Lorenzo Coviello', 'Esteban Moro', 'Manuel Cebrian', 'James H. Fowler']",
         "'Patrick Baylis'",
         "We conduct the largest ever investigation into the relationship between\nmeteorological conditions and the sentiment of human expressions. To do this,\nwe employ over three and a half billion social media posts from tens of\nmillions of individuals from both Facebook and Twitter between 2009 and 2016.\nWe find that cold temperatures, hot temperatures, precipitation, narrower daily\ntemperature ranges, humidity, and cloud cover are all associated with worsened\nexpressions of sentiment, even when excluding weather-related posts. We compare\nthe magnitude of our estimates with the effect sizes associated with notable\nhistorical events occurring within our data.",
         "96",
         "2017"
        ],
        [
         "12063",
         "131731",
         "abs-1904.06941v1",
         "A framework for streamlined statistical prediction using topic models",
         "Applications (Statistics)",
         "stat.AP",
         "2019-04-15",
         "2019-04-15",
         "['Vanessa Glenny', 'Jonathan Tuke', 'Nigel Bean', 'Lewis Mitchell']",
         "'Vanessa Glenny'",
         "In the Humanities and Social Sciences, there is increasing interest in\napproaches to information extraction, prediction, intelligent linkage, and\ndimension reduction applicable to large text corpora. With approaches in these\nfields being grounded in traditional statistical techniques, the need arises\nfor frameworks whereby advanced NLP techniques such as topic modelling may be\nincorporated within classical methodologies. This paper provides a classical,\nsupervised, statistical learning framework for prediction from text, using\ntopic models as a data reduction method and the topics themselves as\npredictors, alongside typical statistical tools for predictive modelling. We\napply this framework in a Social Sciences context (applied animal behaviour) as\nwell as a Humanities context (narrative analysis) as examples of this\nframework. The results show that topic regression models perform comparably to\ntheir much less efficient equivalents that use individual words as predictors.",
         "136",
         "2019"
        ],
        [
         "12064",
         "133271",
         "abs-2202.07081v2",
         "Introducing the ICBe Dataset: Very High Recall and Precision Event\n  Extraction from Narratives about International Crises",
         "Applications (Statistics)",
         "stat.AP",
         "2022-02-14",
         "2022-07-26",
         "['Rex W. Douglass', 'Thomas Leo Scherer', 'J. Andr√©s Gannon', 'Erik Gartzke', 'Jon Lindsay', 'Shannon Carcelli', 'Jonathan Wilkenfeld', 'David M. Quinn', 'Catherine Aiken', 'Jose Miguel Cabezas Navarro', 'Neil Lund', 'Egle Murauskaite', 'Diana Partridge']",
         "'Rex W. Douglass'",
         "How do international crises unfold? We conceptualize of international\nrelations as a strategic chess game between adversaries and develop a\nsystematic way to measure pieces, moves, and gambits accurately and\nconsistently over a hundred years of history. We introduce a new ontology and\ndataset of international events called ICBe based on a very high-quality corpus\nof narratives from the International Crisis Behavior (ICB) Project. We\ndemonstrate that ICBe has higher coverage, recall, and precision than existing\nstate of the art datasets and conduct two detailed case studies of the Cuban\nMissile Crisis (1962) and Crimea-Donbas Crisis (2014). We further introduce two\nnew event visualizations (event icongraphy and crisis maps), an automated\nbenchmark for measuring event recall using natural language processing\n(sythnetic narratives), and an ontology reconstruction task for objectively\nmeasuring event precision. We make the data, online appendix, replication\nmaterial, and visualizations of every historical episode available at a\ncompanion website www.crisisevents.org and the github repository.",
         "156",
         "2022"
        ],
        [
         "12065",
         "134320",
         "abs-2210.11612v2",
         "Searching for a higher power in the human evaluation of MT",
         "Applications (Statistics)",
         "stat.AP",
         "2022-10-20",
         "2022-11-09",
         "['Johnny Tian-Zheng Wei', 'Tom Kocmi', 'Christian Federmann']",
         "'Johnny Tian-Zheng Wei'",
         "In MT evaluation, pairwise comparisons are conducted to identify the better\nsystem. In conducting the comparison, the experimenter must allocate a budget\nto collect Direct Assessment (DA) judgments. We provide a cost effective way to\nspend the budget, but show that typical budget sizes often do not allow for\nsolid comparison. Taking the perspective that the basis of solid comparison is\nin achieving statistical significance, we study the power (rate of achieving\nsignificance) on a large collection of pairwise DA comparisons. Due to the\nnature of statistical estimation, power is low for differentiating less than\n1-2 DA points, and to achieve a notable increase in power requires at least\n2-3x more samples. Applying variance reduction alone will not yield these\ngains, so we must face the reality of undetectable differences and spending\nincreases. In this context, we propose interim testing, an \"early stopping\"\ncollection procedure that yields more power per judgment collected, which\nadaptively focuses the budget on pairs that are borderline significant. Interim\ntesting can achieve up to a 27% efficiency gain when spending 3x the current\nbudget, or 18% savings at the current evaluation power.",
         "187",
         "2022"
        ]
       ],
       "shape": {
        "columns": 12,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "      <th>category_code</th>\n",
       "      <th>published_date</th>\n",
       "      <th>updated_date</th>\n",
       "      <th>authors</th>\n",
       "      <th>first_author</th>\n",
       "      <th>summary</th>\n",
       "      <th>summary_word_count</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12061</th>\n",
       "      <td>131585</td>\n",
       "      <td>abs-1501.03214v1</td>\n",
       "      <td>Quantifying Prosodic Variability in Middle Eng...</td>\n",
       "      <td>Applications (Statistics)</td>\n",
       "      <td>stat.AP</td>\n",
       "      <td>2015-01-14</td>\n",
       "      <td>2015-01-14</td>\n",
       "      <td>['Roger Bilisoly']</td>\n",
       "      <td>'Roger Bilisoly'</td>\n",
       "      <td>Interest in the mathematical structure of poet...</td>\n",
       "      <td>154</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12062</th>\n",
       "      <td>131630</td>\n",
       "      <td>abs-1709.00071v1</td>\n",
       "      <td>Weather impacts expressed sentiment</td>\n",
       "      <td>Applications (Statistics)</td>\n",
       "      <td>stat.AP</td>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>2017-08-31</td>\n",
       "      <td>['Patrick Baylis', 'Nick Obradovich', 'Yury Kr...</td>\n",
       "      <td>'Patrick Baylis'</td>\n",
       "      <td>We conduct the largest ever investigation into...</td>\n",
       "      <td>96</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12063</th>\n",
       "      <td>131731</td>\n",
       "      <td>abs-1904.06941v1</td>\n",
       "      <td>A framework for streamlined statistical predic...</td>\n",
       "      <td>Applications (Statistics)</td>\n",
       "      <td>stat.AP</td>\n",
       "      <td>2019-04-15</td>\n",
       "      <td>2019-04-15</td>\n",
       "      <td>['Vanessa Glenny', 'Jonathan Tuke', 'Nigel Bea...</td>\n",
       "      <td>'Vanessa Glenny'</td>\n",
       "      <td>In the Humanities and Social Sciences, there i...</td>\n",
       "      <td>136</td>\n",
       "      <td>2019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12064</th>\n",
       "      <td>133271</td>\n",
       "      <td>abs-2202.07081v2</td>\n",
       "      <td>Introducing the ICBe Dataset: Very High Recall...</td>\n",
       "      <td>Applications (Statistics)</td>\n",
       "      <td>stat.AP</td>\n",
       "      <td>2022-02-14</td>\n",
       "      <td>2022-07-26</td>\n",
       "      <td>['Rex W. Douglass', 'Thomas Leo Scherer', 'J. ...</td>\n",
       "      <td>'Rex W. Douglass'</td>\n",
       "      <td>How do international crises unfold? We concept...</td>\n",
       "      <td>156</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12065</th>\n",
       "      <td>134320</td>\n",
       "      <td>abs-2210.11612v2</td>\n",
       "      <td>Searching for a higher power in the human eval...</td>\n",
       "      <td>Applications (Statistics)</td>\n",
       "      <td>stat.AP</td>\n",
       "      <td>2022-10-20</td>\n",
       "      <td>2022-11-09</td>\n",
       "      <td>['Johnny Tian-Zheng Wei', 'Tom Kocmi', 'Christ...</td>\n",
       "      <td>'Johnny Tian-Zheng Wei'</td>\n",
       "      <td>In MT evaluation, pairwise comparisons are con...</td>\n",
       "      <td>187</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                id  \\\n",
       "12061      131585  abs-1501.03214v1   \n",
       "12062      131630  abs-1709.00071v1   \n",
       "12063      131731  abs-1904.06941v1   \n",
       "12064      133271  abs-2202.07081v2   \n",
       "12065      134320  abs-2210.11612v2   \n",
       "\n",
       "                                                   title  \\\n",
       "12061  Quantifying Prosodic Variability in Middle Eng...   \n",
       "12062                Weather impacts expressed sentiment   \n",
       "12063  A framework for streamlined statistical predic...   \n",
       "12064  Introducing the ICBe Dataset: Very High Recall...   \n",
       "12065  Searching for a higher power in the human eval...   \n",
       "\n",
       "                        category category_code published_date updated_date  \\\n",
       "12061  Applications (Statistics)       stat.AP     2015-01-14   2015-01-14   \n",
       "12062  Applications (Statistics)       stat.AP     2017-08-31   2017-08-31   \n",
       "12063  Applications (Statistics)       stat.AP     2019-04-15   2019-04-15   \n",
       "12064  Applications (Statistics)       stat.AP     2022-02-14   2022-07-26   \n",
       "12065  Applications (Statistics)       stat.AP     2022-10-20   2022-11-09   \n",
       "\n",
       "                                                 authors  \\\n",
       "12061                                 ['Roger Bilisoly']   \n",
       "12062  ['Patrick Baylis', 'Nick Obradovich', 'Yury Kr...   \n",
       "12063  ['Vanessa Glenny', 'Jonathan Tuke', 'Nigel Bea...   \n",
       "12064  ['Rex W. Douglass', 'Thomas Leo Scherer', 'J. ...   \n",
       "12065  ['Johnny Tian-Zheng Wei', 'Tom Kocmi', 'Christ...   \n",
       "\n",
       "                  first_author  \\\n",
       "12061         'Roger Bilisoly'   \n",
       "12062         'Patrick Baylis'   \n",
       "12063         'Vanessa Glenny'   \n",
       "12064        'Rex W. Douglass'   \n",
       "12065  'Johnny Tian-Zheng Wei'   \n",
       "\n",
       "                                                 summary  summary_word_count  \\\n",
       "12061  Interest in the mathematical structure of poet...                 154   \n",
       "12062  We conduct the largest ever investigation into...                  96   \n",
       "12063  In the Humanities and Social Sciences, there i...                 136   \n",
       "12064  How do international crises unfold? We concept...                 156   \n",
       "12065  In MT evaluation, pairwise comparisons are con...                 187   \n",
       "\n",
       "       year  \n",
       "12061  2015  \n",
       "12062  2017  \n",
       "12063  2019  \n",
       "12064  2022  \n",
       "12065  2022  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data = pd.concat([comp_data, stats_data], axis=0)\n",
    "combined_data.head()\n",
    "combined_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbf5e77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd245f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = combined_data[[\"id\", \"title\", \"summary\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f03da75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-8:\n",
      "Process Process-5:\n",
      "Process Process-4:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/language.py\", line 2409, in _apply_pipes\n",
      "    byte_docs = [(doc.to_bytes(), doc._context, None) for doc in docs]\n",
      "                  ^^^^^^^^^^^^^^\n",
      "  File \"spacy/tokens/doc.pyx\", line 1351, in spacy.tokens.doc.Doc.to_bytes\n",
      "  File \"spacy/tokens/doc.pyx\", line 1411, in spacy.tokens.doc.Doc.to_dict\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/util.py\", line 1350, in to_dict\n",
      "    serialized[key] = getter()\n",
      "                      ^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/language.py\", line 2409, in _apply_pipes\n",
      "    byte_docs = [(doc.to_bytes(), doc._context, None) for doc in docs]\n",
      "                                                                 ^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"spacy/pipeline/transition_parser.pyx\", line 245, in pipe\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/util.py\", line 1650, in minibatch\n",
      "    batch = list(itertools.islice(items, int(batch_size)))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"spacy/pipeline/pipe.pyx\", line 55, in pipe\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"spacy/pipeline/pipe.pyx\", line 55, in pipe\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"spacy/pipeline/transition_parser.pyx\", line 245, in pipe\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/util.py\", line 1650, in minibatch\n",
      "    batch = list(itertools.islice(items, int(batch_size)))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/language.py\", line 2409, in _apply_pipes\n",
      "    byte_docs = [(doc.to_bytes(), doc._context, None) for doc in docs]\n",
      "                                                                 ^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"spacy/pipeline/transition_parser.pyx\", line 245, in pipe\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/util.py\", line 1650, in minibatch\n",
      "    batch = list(itertools.islice(items, int(batch_size)))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"spacy/pipeline/pipe.pyx\", line 55, in pipe\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"spacy/pipeline/pipe.pyx\", line 55, in pipe\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"spacy/pipeline/transition_parser.pyx\", line 245, in pipe\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/util.py\", line 1650, in minibatch\n",
      "    batch = list(itertools.islice(items, int(batch_size)))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "Process Process-6:\n",
      "Process Process-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/language.py\", line 2409, in _apply_pipes\n",
      "    byte_docs = [(doc.to_bytes(), doc._context, None) for doc in docs]\n",
      "                                                                 ^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"spacy/pipeline/transition_parser.pyx\", line 245, in pipe\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/util.py\", line 1650, in minibatch\n",
      "    batch = list(itertools.islice(items, int(batch_size)))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"spacy/pipeline/pipe.pyx\", line 55, in pipe\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"spacy/pipeline/pipe.pyx\", line 55, in pipe\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"spacy/pipeline/transition_parser.pyx\", line 245, in pipe\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/util.py\", line 1650, in minibatch\n",
      "    batch = list(itertools.islice(items, int(batch_size)))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"spacy/pipeline/trainable_pipe.pyx\", line 73, in pipe\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/util.py\", line 1650, in minibatch\n",
      "    batch = list(itertools.islice(items, int(batch_size)))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"spacy/pipeline/trainable_pipe.pyx\", line 75, in pipe\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/pipeline/tok2vec.py\", line 126, in predict\n",
      "    tokvecs = self.model.predict(docs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/model.py\", line 334, in predict\n",
      "    return self._func(self, X, is_train=False)[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/layers/chain.py\", line 54, in forward\n",
      "    Y, inc_layer_grad = layer(X, is_train=is_train)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/layers/with_array.py\", line 42, in forward\n",
      "    return cast(Tuple[SeqT, Callable], _list_forward(model, Xseq, is_train))\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/layers/with_array.py\", line 77, in _list_forward\n",
      "    Yf, get_dXf = layer(Xf, is_train)\n",
      "                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/layers/chain.py\", line 54, in forward\n",
      "    Y, inc_layer_grad = layer(X, is_train=is_train)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/layers/residual.py\", line 41, in forward\n",
      "    Y, backprop_layer = model.layers[0](X, is_train)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/layers/chain.py\", line 54, in forward\n",
      "    Y, inc_layer_grad = layer(X, is_train=is_train)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/layers/chain.py\", line 54, in forward\n",
      "    Y, inc_layer_grad = layer(X, is_train=is_train)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/layers/chain.py\", line 54, in forward\n",
      "    Y, inc_layer_grad = layer(X, is_train=is_train)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/layers/maxout.py\", line 52, in forward\n",
      "    Y = model.ops.gemm(X, W, trans2=True)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/language.py\", line 2409, in _apply_pipes\n",
      "    byte_docs = [(doc.to_bytes(), doc._context, None) for doc in docs]\n",
      "                                                                 ^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"spacy/pipeline/transition_parser.pyx\", line 251, in pipe\n",
      "  File \"spacy/pipeline/transition_parser.pyx\", line 264, in spacy.pipeline.transition_parser.Parser.predict\n",
      "  File \"spacy/pipeline/transition_parser.pyx\", line 285, in spacy.pipeline.transition_parser.Parser.greedy_parse\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/model.py\", line 334, in predict\n",
      "    return self._func(self, X, is_train=False)[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/ml/tb_framework.py\", line 34, in forward\n",
      "    step_model = ParserStepModel(\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"spacy/ml/parser_model.pyx\", line 250, in spacy.ml.parser_model.ParserStepModel.__init__\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/layers/chain.py\", line 54, in forward\n",
      "    Y, inc_layer_grad = layer(X, is_train=is_train)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/layers/chain.py\", line 54, in forward\n",
      "    Y, inc_layer_grad = layer(X, is_train=is_train)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/layers/with_array.py\", line 42, in forward\n",
      "    return cast(Tuple[SeqT, Callable], _list_forward(model, Xseq, is_train))\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/layers/with_array.py\", line 77, in _list_forward\n",
      "    Yf, get_dXf = layer(Xf, is_train)\n",
      "                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/layers/chain.py\", line 54, in forward\n",
      "    Y, inc_layer_grad = layer(X, is_train=is_train)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/layers/residual.py\", line 41, in forward\n",
      "    Y, backprop_layer = model.layers[0](X, is_train)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/layers/chain.py\", line 54, in forward\n",
      "    Y, inc_layer_grad = layer(X, is_train=is_train)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/layers/chain.py\", line 54, in forward\n",
      "    Y, inc_layer_grad = layer(X, is_train=is_train)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/layers/chain.py\", line 54, in forward\n",
      "    Y, inc_layer_grad = layer(X, is_train=is_train)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/layers/maxout.py\", line 52, in forward\n",
      "    Y = model.ops.gemm(X, W, trans2=True)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "Process Process-3:\n",
      "Process Process-2:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/language.py\", line 2409, in _apply_pipes\n",
      "    byte_docs = [(doc.to_bytes(), doc._context, None) for doc in docs]\n",
      "                                                                 ^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"spacy/pipeline/transition_parser.pyx\", line 245, in pipe\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/util.py\", line 1650, in minibatch\n",
      "    batch = list(itertools.islice(items, int(batch_size)))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"spacy/pipeline/pipe.pyx\", line 55, in pipe\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"spacy/pipeline/pipe.pyx\", line 55, in pipe\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"spacy/pipeline/transition_parser.pyx\", line 251, in pipe\n",
      "  File \"spacy/pipeline/transition_parser.pyx\", line 264, in spacy.pipeline.transition_parser.Parser.predict\n",
      "  File \"spacy/pipeline/transition_parser.pyx\", line 285, in spacy.pipeline.transition_parser.Parser.greedy_parse\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/model.py\", line 334, in predict\n",
      "    return self._func(self, X, is_train=False)[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/ml/tb_framework.py\", line 34, in forward\n",
      "    step_model = ParserStepModel(\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"spacy/ml/parser_model.pyx\", line 257, in spacy.ml.parser_model.ParserStepModel.__init__\n",
      "  File \"spacy/ml/parser_model.pyx\", line 398, in spacy.ml.parser_model.precompute_hiddens.__init__\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/ml/_precomputable_affine.py\", line 27, in forward\n",
      "    model.ops.gemm(X, W.reshape((nF * nO * nP, nI)), trans2=True, out=Yf[1:])\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/language.py\", line 2409, in _apply_pipes\n",
      "    byte_docs = [(doc.to_bytes(), doc._context, None) for doc in docs]\n",
      "                                                                 ^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"spacy/pipeline/transition_parser.pyx\", line 245, in pipe\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/util.py\", line 1650, in minibatch\n",
      "    batch = list(itertools.islice(items, int(batch_size)))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"spacy/pipeline/pipe.pyx\", line 55, in pipe\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"spacy/pipeline/pipe.pyx\", line 55, in pipe\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"spacy/pipeline/transition_parser.pyx\", line 251, in pipe\n",
      "  File \"spacy/pipeline/transition_parser.pyx\", line 264, in spacy.pipeline.transition_parser.Parser.predict\n",
      "  File \"spacy/pipeline/transition_parser.pyx\", line 285, in spacy.pipeline.transition_parser.Parser.greedy_parse\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/model.py\", line 334, in predict\n",
      "    return self._func(self, X, is_train=False)[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/ml/tb_framework.py\", line 34, in forward\n",
      "    step_model = ParserStepModel(\n",
      "                 ^^^^^^^^^^^^^^^^\n",
      "  File \"spacy/ml/parser_model.pyx\", line 257, in spacy.ml.parser_model.ParserStepModel.__init__\n",
      "  File \"spacy/ml/parser_model.pyx\", line 398, in spacy.ml.parser_model.precompute_hiddens.__init__\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/ml/_precomputable_affine.py\", line 27, in forward\n",
      "    model.ops.gemm(X, W.reshape((nF * nO * nP, nI)), trans2=True, out=Yf[1:])\n",
      "KeyboardInterrupt\n",
      "Process Process-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/language.py\", line 2409, in _apply_pipes\n",
      "    byte_docs = [(doc.to_bytes(), doc._context, None) for doc in docs]\n",
      "                                                                 ^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"spacy/pipeline/transition_parser.pyx\", line 245, in pipe\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/util.py\", line 1650, in minibatch\n",
      "    batch = list(itertools.islice(items, int(batch_size)))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"spacy/pipeline/pipe.pyx\", line 55, in pipe\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"spacy/pipeline/pipe.pyx\", line 55, in pipe\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"spacy/pipeline/transition_parser.pyx\", line 245, in pipe\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/util.py\", line 1650, in minibatch\n",
      "    batch = list(itertools.islice(items, int(batch_size)))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"spacy/pipeline/trainable_pipe.pyx\", line 73, in pipe\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/util.py\", line 1650, in minibatch\n",
      "    batch = list(itertools.islice(items, int(batch_size)))\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/util.py\", line 1703, in _pipe\n",
      "    yield from proc.pipe(docs, **kwargs)\n",
      "  File \"spacy/pipeline/trainable_pipe.pyx\", line 75, in pipe\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/pipeline/tok2vec.py\", line 126, in predict\n",
      "    tokvecs = self.model.predict(docs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/model.py\", line 334, in predict\n",
      "    return self._func(self, X, is_train=False)[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/layers/chain.py\", line 54, in forward\n",
      "    Y, inc_layer_grad = layer(X, is_train=is_train)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/layers/with_array.py\", line 42, in forward\n",
      "    return cast(Tuple[SeqT, Callable], _list_forward(model, Xseq, is_train))\n",
      "                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/layers/with_array.py\", line 77, in _list_forward\n",
      "    Yf, get_dXf = layer(Xf, is_train)\n",
      "                  ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/layers/chain.py\", line 54, in forward\n",
      "    Y, inc_layer_grad = layer(X, is_train=is_train)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/layers/residual.py\", line 41, in forward\n",
      "    Y, backprop_layer = model.layers[0](X, is_train)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/layers/chain.py\", line 54, in forward\n",
      "    Y, inc_layer_grad = layer(X, is_train=is_train)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/layers/chain.py\", line 54, in forward\n",
      "    Y, inc_layer_grad = layer(X, is_train=is_train)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/layers/chain.py\", line 54, in forward\n",
      "    Y, inc_layer_grad = layer(X, is_train=is_train)\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/model.py\", line 310, in __call__\n",
      "    return self._func(self, X, is_train=is_train)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/thinc/layers/maxout.py\", line 52, in forward\n",
      "    Y = model.ops.gemm(X, W, trans2=True)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "/Users/narenprax/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/language.py:1737: UserWarning: [W127] Not all `Language.pipe` worker processes completed successfully\n",
      "  warnings.warn(Warnings.W127)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Use spaCy's pipe method for faster processing with multithreading\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m tokenized = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnlp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m.\u001b[49m\u001b[43msummary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_process\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# n_process=-1 uses all available cores\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/language.py:1621\u001b[39m, in \u001b[36mLanguage.pipe\u001b[39m\u001b[34m(self, texts, as_tuples, batch_size, disable, component_cfg, n_process)\u001b[39m\n\u001b[32m   1619\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m pipe \u001b[38;5;129;01min\u001b[39;00m pipes:\n\u001b[32m   1620\u001b[39m         docs = pipe(docs)\n\u001b[32m-> \u001b[39m\u001b[32m1621\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1622\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdoc\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/language.py:1701\u001b[39m, in \u001b[36mLanguage._multiprocessing_pipe\u001b[39m\u001b[34m(self, texts, pipes, n_process, batch_size)\u001b[39m\n\u001b[32m   1697\u001b[39m byte_tuples = chain.from_iterable(\n\u001b[32m   1698\u001b[39m     recv.recv() \u001b[38;5;28;01mfor\u001b[39;00m recv \u001b[38;5;129;01min\u001b[39;00m cycle(bytedocs_recv_ch)\n\u001b[32m   1699\u001b[39m )\n\u001b[32m   1700\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1701\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mbyte_doc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbyte_error\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m   1702\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mraw_texts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbyte_tuples\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m   1703\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1704\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbyte_doc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[32m   1705\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mDoc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbyte_doc\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/RRR-datacreation/.venv/lib/python3.12/site-packages/spacy/language.py:1698\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m   1693\u001b[39m     tx.close()\n\u001b[32m   1695\u001b[39m \u001b[38;5;66;03m# Cycle channels not to break the order of docs.\u001b[39;00m\n\u001b[32m   1696\u001b[39m \u001b[38;5;66;03m# The received object is a batch of byte-encoded docs, so flatten them with chain.from_iterable.\u001b[39;00m\n\u001b[32m   1697\u001b[39m byte_tuples = chain.from_iterable(\n\u001b[32m-> \u001b[39m\u001b[32m1698\u001b[39m     \u001b[43mrecv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m recv \u001b[38;5;129;01min\u001b[39;00m cycle(bytedocs_recv_ch)\n\u001b[32m   1699\u001b[39m )\n\u001b[32m   1700\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1701\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, (_, (byte_doc, context, byte_error)) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\n\u001b[32m   1702\u001b[39m         \u001b[38;5;28mzip\u001b[39m(raw_texts, byte_tuples), \u001b[32m1\u001b[39m\n\u001b[32m   1703\u001b[39m     ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/connection.py:250\u001b[39m, in \u001b[36m_ConnectionBase.recv\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28mself\u001b[39m._check_closed()\n\u001b[32m    249\u001b[39m \u001b[38;5;28mself\u001b[39m._check_readable()\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m buf = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_recv_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _ForkingPickler.loads(buf.getbuffer())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/connection.py:430\u001b[39m, in \u001b[36mConnection._recv_bytes\u001b[39m\u001b[34m(self, maxsize)\u001b[39m\n\u001b[32m    429\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_recv_bytes\u001b[39m(\u001b[38;5;28mself\u001b[39m, maxsize=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m     buf = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_recv\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    431\u001b[39m     size, = struct.unpack(\u001b[33m\"\u001b[39m\u001b[33m!i\u001b[39m\u001b[33m\"\u001b[39m, buf.getvalue())\n\u001b[32m    432\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m size == -\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.12/3.12.10/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/connection.py:395\u001b[39m, in \u001b[36mConnection._recv\u001b[39m\u001b[34m(self, size, read)\u001b[39m\n\u001b[32m    393\u001b[39m remaining = size\n\u001b[32m    394\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m remaining > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m     chunk = \u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    396\u001b[39m     n = \u001b[38;5;28mlen\u001b[39m(chunk)\n\u001b[32m    397\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n == \u001b[32m0\u001b[39m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Use spaCy's pipe method for faster processing with multithreading\n",
    "tokenized = list(nlp.pipe(documents.summary, n_process=-1))  # n_process=-1 uses all available cores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ac0056",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
